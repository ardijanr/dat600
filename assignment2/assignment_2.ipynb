{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czjcahcys1yO"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "# In This assignment you are asked to read a data which include 48505 articles (Documents). Then fint the most similar documents using Locality Sensitive Hashing. Follow the lecture covering this topic step by step.\n",
        "\n",
        "## 1. Data is available in Json format and you need to read it. 'https://www.ux.uis.no/~vsetty/data/assignment2_aricles.json' (5 points)\n",
        "## 2. Shingle the documents (10 points)\n",
        "### Tips:\n",
        "* Use string package to cleanup the articles e.g, str.maketrans('', '', string.\n",
        "punctuation)\n",
        "* It is better to convert text to lower case that way you get fewer n-grams\n",
        "* apply ngrams(x.split(), n) using ngrams from nltk on the content + title for computing n-grams, for this data n = 2 is suffcient\n",
        "  * You can use n-gram at word level for this task\n",
        "  * try with different n-gram values \n",
        "  * You can use ngrams from nltk for this\n",
        "\n",
        "## 3. Convert n-grams into binary vector representation for each document. You can do some optimzations if the matrix is too big. (10 points)\n",
        "* For example,\n",
        "\n",
        "  * Select top 10000 most frequent n-grams.\n",
        "  * You may also try smaller values of n (like 2 or 3) which result in fewer n-grams.\n",
        "  * Finally, you can also try sparse matrix representation. Like csr_matrix from scipy.sparse. It works even with full vocabulary.\n",
        "    * Given a list of n-grams for each document, see how to builid a sparse matrix here https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html\n",
        "\n",
        "## 4. We need hash function that maps integers 0, 1, . . . , k − 1 to bucket numbers 0 through k − 1. It might be impossible to avoid collisions but as long as the collions are too many it won't matter much. (10 points)\n",
        "* The simplest would be using the builtin hash() function, it can be for example, hash(rownumber) % Numberofbuckets\n",
        "* You can generate several of these hash functions by xoring a random integer (hash(rownumber)^randint) % Numberofbuckets\n",
        "* It can also be a as simple as (rownumber * randint) % Numberofbuckets\n",
        "\n",
        "## 5. Compute minhash following the faster algorithm from the lecture (10 points)\n",
        "## 6. Hash signature bands into buckets. Find a way to combine all the  signature values in a band and hash them into a number of buckets ususally very high. (10 points)\n",
        "* Easiest way is to add all the signature values in the bucket and use a similar hash function like before\n",
        "* You should use the same hash function for all bands. And all documents ending up in same bucket for at least one band are considered as candidate pairs.\n",
        "\n",
        "## 7. Tune parameters to make sure the threshold is appropriate. (10 points)\n",
        "* plot the probability of two similar items falling in same bucket for different threshold values\n",
        "\n",
        "## 8. Choose the best parameters and get nearest neighbors of each articles (20 points)\n",
        "* Jaccard Similarity\n",
        "* convert hash table into dictionary of article ids and its other articles that hashed in at least 1 same bucket\n",
        "\n",
        "## 9. Write the nearest neibhors of each document to submissions.csv (comma separated, first column is the current document followed by a list of nearest neighbors) file and get the score (10 points)\n",
        "\n",
        "## 10. Write a report + notebook + submission file in a zip file (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yjK4_fGbHYIA"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/home/ardijan/home_actual/repos/algorithms/assignment2/assignment_2.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ardijan/home_actual/repos/algorithms/assignment2/assignment_2.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ardijan/home_actual/repos/algorithms/assignment2/assignment_2.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ardijan/home_actual/repos/algorithms/assignment2/assignment_2.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import nltk\n",
        "from nltk import ngrams\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coy5Lxd6JcaI"
      },
      "outputs": [],
      "source": [
        "def getFrequentNgrams(articles):\n",
        "  # Your code Here\n",
        "    # Select most frequent n-grams\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaAvfYIkJvYf"
      },
      "outputs": [],
      "source": [
        "def getBinaryMatrix(docs):\n",
        "  # Your code Here\n",
        "       # return binary_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HX7R93sYMoM0"
      },
      "outputs": [],
      "source": [
        "def getHashFunctionValues(numrows, numhashfunctions):\n",
        "    # Your code Here\n",
        "    #return a matrix with hash values\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trWgSifwNEQ2"
      },
      "outputs": [],
      "source": [
        "def getMinHashSignatureMatrix(binary_matrix, hash_val_matrix):\n",
        "    #return minhash signature matrix\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRC-FWUSSAON"
      },
      "outputs": [],
      "source": [
        "def getLSH(signature_matrix, num_bands, num_buckets):\n",
        "    #return lsh buckets or hash table\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNmDBSVuSdvV"
      },
      "outputs": [],
      "source": [
        "def plotProbability(s, b, r):\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYqQg7BfVPuN"
      },
      "outputs": [],
      "source": [
        "def getJaccardSimilarityScore(C1, C2):\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qzcoHoGVasE"
      },
      "outputs": [],
      "source": [
        "# convert hash table into dictionary of article ids and its other articles that hashed in at least 1 same bucket\n",
        "nearest_neighbors = {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkEBs1OOWbuZ"
      },
      "outputs": [],
      "source": [
        "# Remove the neighbors in same buckets but have similarity score < threshold s\n",
        "n_copy = copy.deepcopy(nearest_neighbors)\n",
        "submission_id = []\n",
        "submission_nid = []\n",
        "for article_id, neighbor_ids in n_copy.items():\n",
        "    for nid in neighbor_ids:\n",
        "        score = \n",
        "        if score < s:\n",
        "           \n",
        "        else:\n",
        "            # add to submission result\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wivKramXf-1"
      },
      "outputs": [],
      "source": [
        "data = pd.DataFrame()\n",
        "data['article_id'] = submission_id\n",
        "data['neighbor_id'] = submission_nid\n",
        "data.sort_values(by=['article_id', 'neighbor_id'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpqOKfR5Xlqz"
      },
      "outputs": [],
      "source": [
        "data.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fzmz-qQxXpA6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
